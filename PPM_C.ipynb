{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Puy0HMII44S"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from typing import Optional, Tuple, Iterable, List, Dict, Set, Any\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import re\n",
        "import pickle\n",
        "import random\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwqFMdMAHkal"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementação do modelo PPM (Prediction by Partial Matching) - C\n",
        "\n",
        "Descrição geral:\n",
        "- Este arquivo contém uma versão do PPM Modelo C adaptada para uso com uma\n",
        "  biblioteca de codificação aritmética (aqui referida como `arithmeticcoding`).\n",
        "- O PPM é um modelo de previsão de símbolos para compressão de dados baseado em\n",
        "  contextos de tamanho limitado (ordem). O Modelo C usa uma trie onde cada\n",
        "  nó representa um símbolo no contexto e cada nó guarda contagens de ocorrência.\n",
        "- O código inclui:\n",
        "  - Estruturas de nó e árvore (NoPPM_C, ArvorePPM_C)\n",
        "  - Integração com codificação aritmética (entrada/saída de bits)\n",
        "  - Tratamento de símbolos especiais: símbolo de escape e símbolo de fim\n",
        "  - Cálculo de entropia empírica enquanto codifica/decodifica, de modo simétrico\n",
        "  - Funções utilitárias para compactar/descompactar e comparar arquivos\n",
        "\n",
        "Observações técnicas importantes (em alto nível):\n",
        "- A versão usa um dicionário em cada nó para acesso O(1) aos filhos (em média),\n",
        "  ao invés de listas ligadas; isso melhora desempenho em grandes alfabetos.\n",
        "- Mantemos ponteiros \"vine\" (vine/link) para o nó correspondente ao contexto\n",
        "  reduzido (usado para percorrer contextos de ordem decrescente). Essa é uma\n",
        "  otimização típica em PPM para acelerar busca de contextos menores.\n",
        "- Para interagir com a codificação aritmética, este código constrói tabelas de\n",
        "  frequência (SimpleFrequencyTable) a cada nível de contexto. Há um limite de\n",
        "  somatório (limite) para escalar contagens muito grandes e evitar overflow.\n",
        "- O símbolo de escape (_SIMBOLO_ESCAPE) é usado quando um símbolo não é\n",
        "  observado no contexto atual: codifica-se uma ocorrência de escape e desce-se\n",
        "  para contexto menor.\n",
        "- O símbolo de fim (_SIMBOLO_FIM) é codificado ao finalizar a compressão para\n",
        "  sinalizar término durante a descompressão.\n",
        "\"\"\"\n",
        "# Tenta importar a biblioteca de codificação aritmética implementada por Nayuki. Se não existir, termina.\n",
        "try:\n",
        "    import arithmeticcoding\n",
        "except ImportError:\n",
        "    print(\"Erro: A biblioteca 'arithmetic-coding' não foi encontrada.\")\n",
        "    raise\n",
        "\n",
        "# -------------------\n",
        "# Símbolos especiais\n",
        "# -------------------\n",
        "# Usamos objetos únicos para representar ESCAPE e EOF. Não utilizamos\n",
        "# valores inteiros fixos aqui para evitar colisões com símbolos válidos do\n",
        "# alfabeto. Esses objetos são usados como chaves nos dicionários.\n",
        "_SIMBOLO_ESCAPE = object()\n",
        "_SIMBOLO_FIM = object()\n",
        "\n",
        "# ---------------------------------\n",
        "# Definição do nó da trie (NoPPM_C)\n",
        "# ---------------------------------\n",
        "class NoPPM_C:\n",
        "    \"\"\"\n",
        "    Nó da trie para modelo PPM.\n",
        "\n",
        "    Atributos principais:\n",
        "    - simbolo: o símbolo representado por este nó (None para raiz).\n",
        "    - contagem: número de vezes que o símbolo foi observado no contexto que o\n",
        "      nó representa.\n",
        "    - filhos: dicionário mapeando simbolo -> NoPPM_C (acesso O(1) médio).\n",
        "    - vine: ponteiro para o próximo nó no encadeamento de contexto (equivale\n",
        "      ao 'sufixo' / contexto reduzido). Usado para descer para contextos menores\n",
        "      durante a codificação/decodificação.\n",
        "    - pai: ponteiro para o nó pai (útil para navegação/atualizações).\n",
        "    - nivel: profundidade do nó (0 para raiz, 1 para primeiro nível, ...)\n",
        "\n",
        "    Observações de implementação:\n",
        "    - __slots__ reduz o overhead de memória por nó, importante em tries\n",
        "      grandes.\n",
        "    - Ao criar filhos, inicializamos com contagem 1\n",
        "    \"\"\"\n",
        "\n",
        "    __slots__ = (\"simbolo\", \"contagem\", \"filhos\", \"vine\", \"pai\", \"nivel\")\n",
        "\n",
        "    def __init__(self, simbolo: Optional[Any], nivel: int = 0, pai: Optional[\"NoPPM_C\"] = None):\n",
        "        # simbolo: valor do símbolo (int para bytes, ou objetos especiais)\n",
        "        self.simbolo: Optional[Any] = simbolo\n",
        "\n",
        "        # contagem de ocorrências no contexto representado por este nó\n",
        "        self.contagem: int = 1\n",
        "\n",
        "        # filhos: dicionário para acesso rápido\n",
        "        self.filhos: Dict[Any, NoPPM_C] = {}\n",
        "\n",
        "        # vine: link para o nó que representa o contexto reduzido\n",
        "        self.vine: Optional[\"NoPPM_C\"] = None\n",
        "\n",
        "        # pai: nó pai na trie\n",
        "        self.pai: Optional[\"NoPPM_C\"] = pai\n",
        "\n",
        "        # nivel: profundidade (0 = raiz, a qual corresponde a coluna k = -1, seguindo a notação vista em sala)\n",
        "        self.nivel: int = nivel\n",
        "\n",
        "    def encontrar_filho(self, simbolo: Any) -> Optional[\"NoPPM_C\"]:\n",
        "        #Retorna o filho para o símbolo dado ou None se não existir.\n",
        "\n",
        "        return self.filhos.get(simbolo)\n",
        "\n",
        "    def obter_ou_adicionar_filho(self, simbolo: Any, contagem_inicial: int = 1) -> Tuple[\"NoPPM_C\", bool]:\n",
        "        \"\"\"\n",
        "        Retorna (filho, criado_flag).\n",
        "\n",
        "        Se o filho existir, retorna o nó existente e False. Caso contrário,\n",
        "        cria um novo nó com contagem inicial e retorna True no segundo elemento.\n",
        "        \"\"\"\n",
        "        existente = self.encontrar_filho(simbolo)\n",
        "        if existente:\n",
        "            return existente, False\n",
        "\n",
        "        novo_filho = NoPPM_C(simbolo=simbolo, nivel=self.nivel + 1, pai=self)\n",
        "        novo_filho.contagem = contagem_inicial\n",
        "        self.filhos[simbolo] = novo_filho\n",
        "\n",
        "        return novo_filho, True\n",
        "\n",
        "    def obter_ou_criar_no_escape(self) -> Tuple[\"NoPPM_C\", bool]:\n",
        "        #Conveniência para obter/criar o nó de escape no conjunto de filhos.\n",
        "        return self.obter_ou_adicionar_filho(_SIMBOLO_ESCAPE, contagem_inicial=1)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        if self.simbolo is None:\n",
        "            return \"<RAIZ>\"\n",
        "        if self.simbolo is _SIMBOLO_ESCAPE:\n",
        "            return f\"<ESC,{self.contagem}>\"\n",
        "        return f\"<{self.simbolo},{self.contagem}>\"\n",
        "\n",
        "# -----------------------------\n",
        "# Arvore PPM (ArvorePPM_C)\n",
        "# -----------------------------\n",
        "class ArvorePPM_C:\n",
        "    \"\"\"\n",
        "    Implementação do modelo PPM-C com integração à codificação\n",
        "    aritmética.\n",
        "\n",
        "    Campos principais:\n",
        "    - ordem: ordem máxima do modelo (tamanho do contexto máximo em símbolos).\n",
        "    - tamanho_alfabeto_bytes: tamanho do alfabeto básico (por exemplo 256 para bytes).\n",
        "    - tamanho_alfabeto_total: alfabeto + símbolos especiais (escape e fim).\n",
        "    - simbolo_para_int/int_para_simbolo: mapeamentos para tabela de frequências.\n",
        "    - raiz/base/contexto: estruturas de navegação da trie.\n",
        "    - soma_entropia/contagem_simbolos: para cálculo empírico da entropia H(X).\n",
        "\n",
        "    Observações detalhadas:\n",
        "    - A classe constrói tabelas de frequência a partir das contagens observadas\n",
        "      em cada contexto e passa essas tabelas para o codificador/decodificador\n",
        "      aritmético.\n",
        "    - O método _criar_tabela_frequencia aplica uma escala/normalização quando\n",
        "      a soma das contagens excede um limite (para evitar números muito grandes).\n",
        "    - Os métodos codificar_simbolo e decodificar_simbolo mantêm a simetria do\n",
        "      cálculo de entropia para comparação entre compressão e descompressão.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ordem: int, tamanho_alfabeto: int = 256, fluxo_bits: io.BytesIO = None):\n",
        "        if ordem < 0:\n",
        "            raise ValueError(\"A ordem deve ser >= 0.\")\n",
        "        self.ordem: int = ordem\n",
        "        self.tamanho_alfabeto_bytes = tamanho_alfabeto\n",
        "        self.tamanho_alfabeto_total = tamanho_alfabeto + 2\n",
        "\n",
        "        # Inicializa mapeamentos símbolo <-> inteiro (necessários para a tabela de frequência)\n",
        "        self.simbolo_para_int: Dict[Any, int] = {i: i for i in range(tamanho_alfabeto)}\n",
        "        self.int_para_simbolo: Dict[int, Any] = {i: i for i in range(tamanho_alfabeto)}\n",
        "\n",
        "        esc_int = tamanho_alfabeto\n",
        "        fim_int = tamanho_alfabeto + 1\n",
        "\n",
        "        self.simbolo_para_int[_SIMBOLO_ESCAPE] = esc_int\n",
        "        self.int_para_simbolo[esc_int] = _SIMBOLO_ESCAPE\n",
        "        self.simbolo_para_int[_SIMBOLO_FIM] = fim_int\n",
        "        self.int_para_simbolo[fim_int] = _SIMBOLO_FIM\n",
        "\n",
        "        # Raiz/Base/Contexto para navegar na trie\n",
        "        self.raiz: NoPPM_C = NoPPM_C(simbolo=None, nivel=0)\n",
        "        self.base: NoPPM_C = self.raiz\n",
        "        self.contexto: Tuple[int, ...] = tuple()\n",
        "\n",
        "        # Para o cálculo empírico de entropia\n",
        "        self.soma_entropia = 0.0\n",
        "        self.contagem_simbolos = 0\n",
        "\n",
        "        # Inicializa codificador/decodificador de acordo com o fluxo de bits\n",
        "        if fluxo_bits:\n",
        "            # Modo de decodificação (leitura de um fluxo já existente)\n",
        "            self.leitor_bits = arithmeticcoding.BitInputStream(fluxo_bits)\n",
        "            self.decodificador = arithmeticcoding.ArithmeticDecoder(32, self.leitor_bits)\n",
        "        else:\n",
        "            # Modo de codificação (escreve em um buffer interno)\n",
        "            self.escritor_bits = arithmeticcoding.BitOutputStream(io.BytesIO())\n",
        "            self.codificador = arithmeticcoding.ArithmeticEncoder(32, self.escritor_bits)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Métodos auxiliares para probabilidades e tabelas\n",
        "    # -----------------------------\n",
        "    def _obter_probabilidades(self, no_contexto: NoPPM_C, simbolos_excluidos: Set[Any]) -> Optional[Dict[Any, int]]:\n",
        "        \"\"\"\n",
        "        Retorna um dicionário símbolo -> contagem para os filhos visíveis do nó de\n",
        "        contexto, ignorando símbolos que já foram excluídos (já vistos em\n",
        "        contextos maiores ou processados como escapes).\n",
        "\n",
        "        Retorna None se não houver filhos visíveis ou se a soma das contagens for 0.\n",
        "        \"\"\"\n",
        "        filhos = no_contexto.filhos.values()\n",
        "        visiveis = [c for c in filhos if c.simbolo not in simbolos_excluidos]\n",
        "\n",
        "        if not visiveis:\n",
        "            return None\n",
        "\n",
        "        total = sum(c.contagem for c in visiveis)\n",
        "\n",
        "        if total == 0:\n",
        "            return None\n",
        "\n",
        "        return {c.simbolo: c.contagem for c in visiveis}\n",
        "\n",
        "    def _criar_tabela_frequencia(self, probs: Dict[Any, int]) -> arithmeticcoding.SimpleFrequencyTable:\n",
        "        \"\"\"\n",
        "        Constrói uma SimpleFrequencyTable usada pela codificação aritmética a partir\n",
        "        do dicionário de probabilidades (contagens) 'probs'.\n",
        "\n",
        "        Cria uma lista de frequências do tamanho do alfabeto total e\n",
        "        coloca a contagem correspondente na posição inteira do símbolo.\n",
        "\n",
        "        Quando a soma total das contagens excede um limite predefinido (limite),\n",
        "        aplicamos uma normalização/escala para evitar frequências muito grandes\n",
        "        que possam causar overflow/ineficiências na implementação da aritmética.\n",
        "\n",
        "        A escala é feita proporcionalmente; garantimos que qualquer símbolo com\n",
        "        contagem > 0 tenha pelo menos frequência 1 após a escala (evita elementos\n",
        "        arredondados para zero que quebrariam o modelo).\n",
        "        \"\"\"\n",
        "        frequencias = [0] * self.tamanho_alfabeto_total\n",
        "        total = sum(probs.values())\n",
        "        limite = (1 << 14)  # Limite arbitrário alto para manter números pequenos\n",
        "\n",
        "        if total > limite:\n",
        "            for simbolo, contagem in probs.items():\n",
        "                simbolo_int = self.simbolo_para_int[simbolo]\n",
        "                contagem_escalada = (contagem * limite + total // 2) // total\n",
        "\n",
        "                if contagem > 0 and contagem_escalada == 0:\n",
        "                    # Protege contra arredondamento para 0\n",
        "                    frequencias[simbolo_int] = 1\n",
        "                else:\n",
        "                    frequencias[simbolo_int] = contagem_escalada\n",
        "        else:\n",
        "            for simbolo, contagem in probs.items():\n",
        "                simbolo_int = self.simbolo_para_int[simbolo]\n",
        "                frequencias[simbolo_int] = contagem\n",
        "\n",
        "        return arithmeticcoding.SimpleFrequencyTable(frequencias)\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Atualização do modelo (inserção/atualização de nós)\n",
        "    # ---------------------------------------------------\n",
        "    def _atualizar_modelo(self, simbolo: Any) -> None:\n",
        "        \"\"\"\n",
        "        Atualiza a trie com a observação do símbolo dado, iniciando a partir do\n",
        "        nó base (contexto atual) e subindo/descendo pela cadeia de vine conforme\n",
        "        necessário.\n",
        "\n",
        "        O algoritmo realiza o seguinte, em cada contexto desde o atual até None:\n",
        "        - Tenta obter (ou criar) o filho correspondente ao símbolo\n",
        "        - Liga o filho anterior atualizado pelo campo `vine` para manter\n",
        "          encadeamentos entre os nós recém-criados (otimização de navegação)\n",
        "        - Se o filho foi criado: garante existência do nó de escape no nó atual\n",
        "          e segue para o vine do contexto (continua a atualizar em contextos\n",
        "          menores)\n",
        "        - Se o filho já existia: incrementa sua contagem e interrompe (pois a\n",
        "          observação já está integrada no nó para contextos maiores)\n",
        "\n",
        "        Finalmente atualiza o contexto corrente (self.contexto) e a base (self.base)\n",
        "        para refletir o novo símbolo.\n",
        "\n",
        "        Notas:\n",
        "        - Tratamento de símbolos especiais: se o símbolo não for inteiro (por ex.\n",
        "          _SIMBOLO_ESCAPE ou _SIMBOLO_FIM) reiniciamos o contexto para tuple()\n",
        "          (isso evita usar símbolos especiais como parte do contexto para bytes).\n",
        "        \"\"\"\n",
        "        no_contexto = self.base\n",
        "        no_atualizado_anterior = None\n",
        "\n",
        "        while no_contexto is not None:\n",
        "            filho, criado = no_contexto.obter_ou_adicionar_filho(simbolo)\n",
        "\n",
        "            if no_atualizado_anterior:\n",
        "                # linka o nó atualizado anteriormente para o novo filho\n",
        "                no_atualizado_anterior.vine = filho\n",
        "            no_atualizado_anterior = filho\n",
        "\n",
        "            if criado:\n",
        "                # Se criamos um novo filho, garantimos que exista um nó de escape\n",
        "                if no_contexto.encontrar_filho(_SIMBOLO_ESCAPE):\n",
        "                    no_contexto.filhos[_SIMBOLO_ESCAPE].contagem += 1\n",
        "                else:\n",
        "                    no_contexto.obter_ou_criar_no_escape()\n",
        "                # Desce para o vine do contexto (contexto menor)\n",
        "                no_contexto = no_contexto.vine\n",
        "            else:\n",
        "                # Se o filho já existia, apenas incrementamos e paramos\n",
        "                filho.contagem += 1\n",
        "                break\n",
        "\n",
        "        # Atualiza o contexto (desconsidera símbolos especiais)\n",
        "        if isinstance(simbolo, int):\n",
        "            self.contexto = (self.contexto + (simbolo,))[-self.ordem:]\n",
        "        else:\n",
        "            # Símbolos especiais não fazem parte do contexto\n",
        "            self.contexto = tuple()\n",
        "\n",
        "        # Recalcula self.base descendo a partir da raiz usando o novo contexto\n",
        "        self.base = self.raiz\n",
        "\n",
        "        for s in self.contexto:\n",
        "            prox = self.base.encontrar_filho(s)\n",
        "            if not prox:\n",
        "                break\n",
        "            self.base = prox\n",
        "\n",
        "    # -----------------------------\n",
        "    # Codificação de um símbolo (usando PPM com escapes)\n",
        "    # -----------------------------\n",
        "    def codificar_simbolo(self, simbolo: Any) -> None:\n",
        "        \"\"\"\n",
        "        Codifica o símbolo passado usando o modelo PPM atual juntamente com o\n",
        "        codificador aritmético.\n",
        "\n",
        "        Algoritmo:\n",
        "        - Começa no contexto atual (self.base) e tenta achar probabilidades\n",
        "          condicionais (filhos visíveis)\n",
        "        - Se o símbolo aparece nas probabilidades do contexto atual: codifica-o\n",
        "          diretamente com a tabela e atualiza o modelo\n",
        "        - Se não aparece, mas há símbolo de escape no contexto: codifica o\n",
        "          símbolo de escape e desce para o vine (contexto menor), repetindo\n",
        "        - Se chegamos a nenhum contexto com probabilidades (ordem -1), usamos\n",
        "          a equiprobabilidade sobre os símbolos restantes (aqueles que não\n",
        "          foram excluídos) e codificamos com essa tabela\n",
        "\n",
        "        Além disso, calculamos a entropia empírica acumulando -log2(p) onde p é\n",
        "        a probabilidade usada para representar o símbolo.\n",
        "        \"\"\"\n",
        "        simbolo_int = self.simbolo_para_int[simbolo]\n",
        "        excluidos = set()\n",
        "        no_contexto = self.base\n",
        "        while no_contexto is not None:\n",
        "            probs = self._obter_probabilidades(no_contexto, excluidos)\n",
        "            if probs and simbolo in probs:\n",
        "                # Caso 1: símbolo encontrado no contexto atual\n",
        "                tabela = self._criar_tabela_frequencia(probs)\n",
        "                total = sum(probs.values())\n",
        "                prob_simbolo = probs[simbolo] / total\n",
        "                # Acumula entropia para análise (simetria entre codificar/decodificar)\n",
        "                self.soma_entropia += -math.log2(prob_simbolo)\n",
        "                self.contagem_simbolos += 1\n",
        "                # Escreve o símbolo usando a tabela do contexto\n",
        "                self.codificador.write(tabela, simbolo_int)\n",
        "                # Atualiza o modelo com a observação\n",
        "                self._atualizar_modelo(simbolo)\n",
        "                return\n",
        "            # Caso 2: símbolo não encontrado no contexto atual\n",
        "            if probs and _SIMBOLO_ESCAPE in probs:\n",
        "                #Codifica o símbolo de escape (se existe na tabela) para indicar\n",
        "                #Que devemos descer para contexto menor\n",
        "                tabela = self._criar_tabela_frequencia(probs)\n",
        "                self.codificador.write(tabela, self.simbolo_para_int[_SIMBOLO_ESCAPE])\n",
        "\n",
        "            # Exclui todos os símbolos visíveis neste nó para não contá-los\n",
        "            # Novamente em contextos menores\n",
        "            excluidos.update(c.simbolo for c in no_contexto.filhos.values() if c.simbolo is not _SIMBOLO_ESCAPE)\n",
        "            # Segue para contexto menor via vine\n",
        "            no_contexto = no_contexto.vine\n",
        "\n",
        "        #Caso 3: contexto de ordem -1\n",
        "        todos = set(self.simbolo_para_int.keys()) - {_SIMBOLO_ESCAPE}\n",
        "        restantes = sorted(list(todos - excluidos), key=lambda s: self.simbolo_para_int[s])\n",
        "\n",
        "        if restantes:\n",
        "            #Probabilidade uniforme (equiprobabilidade) sobre símbolos restantes\n",
        "            prob_simbolo = 1 / len(restantes)\n",
        "            self.soma_entropia += -math.log2(prob_simbolo)\n",
        "            self.contagem_simbolos += 1\n",
        "\n",
        "        #Constrói tabela com freq 1 para cada símbolo restante (fallback básico)\n",
        "        freqs = [0] * self.tamanho_alfabeto_total\n",
        "\n",
        "        for s in restantes:\n",
        "            freqs[self.simbolo_para_int[s]] = 1\n",
        "\n",
        "        self.codificador.write(arithmeticcoding.SimpleFrequencyTable(freqs), simbolo_int)\n",
        "        self._atualizar_modelo(simbolo)\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Decodificação de um símbolo (simétrica à codificação)\n",
        "    # -----------------------------------------------------\n",
        "    def decodificar_simbolo(self) -> Any:\n",
        "        \"\"\"\n",
        "        Decodifica um símbolo a partir do fluxo de bits usando o modelo PPM\n",
        "        atual e o decodificador aritmético.\n",
        "\n",
        "        Procedimento:\n",
        "        - Na ordem, tenta construir a tabela a partir do contexto atual\n",
        "        - Usa o decodificador aritmético para ler um inteiro indexado pela tabela\n",
        "        - Se o inteiro corresponder ao símbolo de escape, desce para contexto menor\n",
        "        - Se corresponder a um símbolo real, atualiza entropia (simetricamente)\n",
        "          e retorna o símbolo\n",
        "        - Se nenhum contexto produz probabilidades (ordem -1), usa o fallback\n",
        "          uniforme sobre símbolos restantes (mesma tabela construída durante a\n",
        "          codificação)\n",
        "        \"\"\"\n",
        "        excluidos = set()\n",
        "        no_contexto = self.base\n",
        "\n",
        "        while no_contexto is not None:\n",
        "            probs = self._obter_probabilidades(no_contexto, excluidos)\n",
        "\n",
        "            if probs:\n",
        "                tabela = self._criar_tabela_frequencia(probs)\n",
        "                decod_int = self.decodificador.read(tabela)\n",
        "                simbolo = self.int_para_simbolo[decod_int]\n",
        "\n",
        "                if simbolo is not _SIMBOLO_ESCAPE:\n",
        "                    # Se é um símbolo real, atualiza entropia (mantendo simetria)\n",
        "                    total = sum(probs.values())\n",
        "\n",
        "                    if total > 0 and simbolo in probs and probs[simbolo] > 0:\n",
        "                        prob_simbolo = probs[simbolo] / total\n",
        "                        self.soma_entropia += -math.log2(prob_simbolo)\n",
        "                        self.contagem_simbolos += 1\n",
        "\n",
        "                    self._atualizar_modelo(simbolo)\n",
        "                    return simbolo\n",
        "\n",
        "            # Se descodificou ESCAPE ou não há probs, marca símbolos deste nó\n",
        "            excluidos.update(c.simbolo for c in no_contexto.filhos.values() if c.simbolo is not _SIMBOLO_ESCAPE)\n",
        "            no_contexto = no_contexto.vine\n",
        "\n",
        "        # Fallback ordem -1\n",
        "        todos = set(self.simbolo_para_int.keys()) - {_SIMBOLO_ESCAPE}\n",
        "        restantes = sorted(list(todos - excluidos), key=lambda s: self.simbolo_para_int[s])\n",
        "\n",
        "        if restantes:\n",
        "            prob_simbolo = 1 / len(restantes)\n",
        "            self.soma_entropia += -math.log2(prob_simbolo)\n",
        "            self.contagem_simbolos += 1\n",
        "\n",
        "        freqs = [0] * self.tamanho_alfabeto_total\n",
        "\n",
        "        for s in restantes:\n",
        "            freqs[self.simbolo_para_int[s]] = 1\n",
        "\n",
        "        decod_int = self.decodificador.read(arithmeticcoding.SimpleFrequencyTable(freqs))\n",
        "        simbolo = self.int_para_simbolo[decod_int]\n",
        "        self._atualizar_modelo(simbolo)\n",
        "\n",
        "        return simbolo\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # Finalização da compressão (escreve EOF e flush)\n",
        "    # -----------------------------------------------\n",
        "    def finalizar_compressao(self) -> bytes:\n",
        "        \"\"\"\n",
        "        Escreve o símbolo de fim e finaliza o codificador aritmético, retornando\n",
        "        o buffer de bytes resultante.\n",
        "\n",
        "        Também escreve bits de padding (zeros) até que o último byte seja\n",
        "        completado, conforme a interface do BitOutputStream usado.\n",
        "        \"\"\"\n",
        "        self.codificar_simbolo(_SIMBOLO_FIM)\n",
        "        self.codificador.finish()\n",
        "\n",
        "        while self.escritor_bits.numbitsfilled != 0:\n",
        "            self.escritor_bits.write(0)\n",
        "\n",
        "        resultado = self.escritor_bits.output.getvalue()\n",
        "        self.escritor_bits.output.close()\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    # -----------------------------\n",
        "    # Persistência do modelo (salvar/carregar)\n",
        "    # -----------------------------\n",
        "    def salvar_modelo(self, nome_arquivo: str):\n",
        "        #Salva o objeto da árvore (self) em pickle para reutilização posterior\n",
        "        with open(nome_arquivo, \"wb\") as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    @staticmethod\n",
        "    def carregar_modelo(nome_arquivo: str) -> \"ArvorePPM_C\":\n",
        "        #Carrega um modelo salvo via pickle e retorna a instância.\n",
        "        with open(nome_arquivo, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Geração de texto (a partir do modelo treinado)\n",
        "    # -----------------------------\n",
        "    def gerar_texto(self, tamanho: int, semente: str = \"\") -> str:\n",
        "        \"\"\"\n",
        "        Gera texto aleatório de comprimento `tamanho` usando as distribuições\n",
        "        condicionais aprendidas pelo modelo. A semente (seed) é incorporada ao\n",
        "        contexto inicial para condicionar a geração, caso desejado.\n",
        "\n",
        "        Estratégia:\n",
        "        - Percorre contextos do maior para o menor (via vine) procurando símbolos\n",
        "          inteiros (bytes) visíveis e seleciona aleatoriamente segundo as\n",
        "          probabilidades empíricas normalizadas, ou seja, considerando as probabilidades\n",
        "          como pesos.\n",
        "        - Se não encontra símbolo nos contextos, usa os símbolos disponíveis na raiz\n",
        "          como fallback (evita falha quando a trie está escassa).\n",
        "        \"\"\"\n",
        "        resultado: List[str] = []\n",
        "        # Incorpora a semente ao contexto (cada caractere -> código inteiro)\n",
        "        for ch in semente:\n",
        "            simbolo_int = ord(ch)\n",
        "            self._atualizar_modelo(simbolo_int)\n",
        "            resultado.append(ch)\n",
        "\n",
        "        for _ in range(tamanho):\n",
        "            no_atual = self.base\n",
        "            excluidos: Set[Any] = set()\n",
        "            escolhido: Optional[int] = None\n",
        "\n",
        "            while no_atual is not None:\n",
        "                probs = self._obter_probabilidades(no_atual, excluidos)\n",
        "                if probs:\n",
        "                    # Usamos apenas símbolos inteiros para saída textual\n",
        "                    probs_validas = {s: c for s, c in probs.items() if isinstance(s, int)}\n",
        "\n",
        "                    if probs_validas:\n",
        "                        simbolos, pesos = zip(*probs_validas.items())\n",
        "                        total = sum(pesos)\n",
        "                        pesos = [p / total for p in pesos]\n",
        "                        escolhido = random.choices(simbolos, weights=pesos, k=1)[0]\n",
        "                        break\n",
        "\n",
        "                excluidos.update(c.simbolo for c in no_atual.filhos.values() if isinstance(c.simbolo, int))\n",
        "                no_atual = no_atual.vine\n",
        "\n",
        "            if escolhido is None:\n",
        "                # Fallback para símbolos disponíveis na raiz (se houver)\n",
        "                disponiveis = [s for s in self.raiz.filhos.keys() if isinstance(s, int)]\n",
        "                escolhido = random.choice(disponiveis) if disponiveis else ord(' ')\n",
        "\n",
        "            self._atualizar_modelo(escolhido)\n",
        "            resultado.append(chr(escolhido))\n",
        "\n",
        "        return ''.join(resultado)\n",
        "    \n",
        "    def gerar_texto_nitidez(self, tamanho: int, semente: str = \"\", nitidez: float = 1.0) -> str:\n",
        "        \"\"\"\n",
        "        Gera texto aleatório com saídas de depuração detalhadas a cada passo.\n",
        "\n",
        "        Para cada símbolo a ser gerado, esta função imprime:\n",
        "        - O contexto atual a partir do qual a previsão é feita.\n",
        "        - As probabilidades dos símbolos candidatos, mostrando a original e a ajustada.\n",
        "        - O símbolo que foi efetivamente escolhido com base nessas probabilidades.\n",
        "\n",
        "        Parâmetros:\n",
        "        - tamanho (int): Quantidade de caracteres a serem gerados.\n",
        "        - semente (str): Texto inicial para condicionar a geração.\n",
        "        - nitidez (float): Fator para ajustar a distribuição de probabilidade.\n",
        "            - nitidez > 1.0: Torna as escolhas mais prováveis ainda mais prováveis (menos aleatório).\n",
        "            - nitidez = 1.0: Comportamento padrão, sem ajustes.\n",
        "            - 0.0 < nitidez < 1.0: Torna as escolhas mais aleatórias, achatando a distribuição.\n",
        "        \"\"\"\n",
        "\n",
        "        resultado: List[str] = []\n",
        "        # Incorpora a semente ao contexto, se houver\n",
        "        if semente:\n",
        "            for ch in semente:\n",
        "                simbolo_int = ord(ch)\n",
        "                self._atualizar_modelo(simbolo_int)\n",
        "                resultado.append(ch)\n",
        "\n",
        "        for i in range(tamanho):\n",
        "            contexto_str = ''.join(map(chr, self.contexto))\n",
        "\n",
        "            no_atual = self.base\n",
        "            excluidos: Set[Any] = set()\n",
        "            escolhido: Optional[int] = None\n",
        "            found_in_context = False\n",
        "\n",
        "            while no_atual is not None:\n",
        "                probs = self._obter_probabilidades(no_atual, excluidos)\n",
        "                if probs:\n",
        "                    # Filtra para manter apenas símbolos que são bytes/inteiros\n",
        "                    probs_validas = {s: c for s, c in probs.items() if isinstance(s, int)}\n",
        "\n",
        "                    if probs_validas:\n",
        "\n",
        "                        # Ordena por contagem para melhor visualização\n",
        "                        sorted_probs = sorted(probs_validas.items(), key=lambda item: -item[1])\n",
        "                        simbolos = [item[0] for item in sorted_probs]\n",
        "                        pesos_originais = [item[1] for item in sorted_probs]\n",
        "                        \n",
        "                        # Aplica o fator de nitidez para inflar/achatar as probabilidades\n",
        "                        # Elevar a contagem a uma potência > 1 infla as maiores contagens\n",
        "                        pesos_ajustados = [p ** nitidez for p in pesos_originais]\n",
        "\n",
        "                        total_original = sum(pesos_originais)\n",
        "                        total_ajustado = sum(pesos_ajustados)\n",
        "                        \n",
        "                        for idx, s in enumerate(simbolos):\n",
        "                            p_original = pesos_originais[idx]\n",
        "                            p_ajustado = pesos_ajustados[idx]\n",
        "                            \n",
        "                            prob_orig_percent = (p_original / total_original) * 100 if total_original > 0 else 0\n",
        "                            prob_ajus_percent = (p_ajustado / total_ajustado) * 100 if total_ajustado > 0 else 0\n",
        "\n",
        "                        # Realiza a escolha aleatória ponderada com os pesos ajustados\n",
        "                        escolhido = random.choices(simbolos, weights=pesos_ajustados, k=1)[0]\n",
        "                        \n",
        "                        found_in_context = True\n",
        "                        break\n",
        "\n",
        "                excluidos.update(c.simbolo for c in no_atual.filhos.values() if isinstance(c.simbolo, int))\n",
        "                no_atual = no_atual.vine\n",
        "\n",
        "            if not found_in_context:\n",
        "                disponiveis = [s for s in self.raiz.filhos.keys() if isinstance(s, int)]\n",
        "                if disponiveis:\n",
        "                    escolhido = random.choice(disponiveis)\n",
        "                else:\n",
        "                    escolhido = ord(' ')\n",
        "\n",
        "            self._atualizar_modelo(escolhido)\n",
        "            resultado.append(chr(escolhido))\n",
        "\n",
        "        texto_gerado = ''.join(resultado)\n",
        "\n",
        "        return texto_gerado\n",
        "    \n",
        "    def calcular_perplexidade(self) -> float:\n",
        "        \"\"\"\n",
        "        Calcula a perplexidade com base na entropia acumulada.\n",
        "        Deve ser chamada após o processamento de um texto (compressão/descompressão).\n",
        "        Retorna float('inf') se nenhum símbolo foi processado.\n",
        "        \"\"\"\n",
        "        if self.contagem_simbolos == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        entropia_media = self.soma_entropia / self.contagem_simbolos\n",
        "        perplexidade = math.pow(2, entropia_media)\n",
        "        return perplexidade\n",
        "\n",
        "# --------------------\n",
        "# Funções utilitárias\n",
        "# --------------------\n",
        "\n",
        "def comprimir(entrada: str, saida: str, ordem: int):\n",
        "    \"\"\"\n",
        "    Compacta o arquivo `entrada` para `saida` usando um modelo PPM de ordem\n",
        "    `ordem`. Retorna (tempo_em_segundos, instancia_compressor).\n",
        "\n",
        "    Passos:\n",
        "    - Cria instância ArvorePPM_C para codificação\n",
        "    - Lê o arquivo byte a byte e chama codificar_simbolo para cada byte\n",
        "    - Finaliza a compressão escrevendo o buffer resultante em `saida`\n",
        "    \"\"\"\n",
        "    print(f\"Iniciando compressão de '{entrada}'...\")\n",
        "\n",
        "    inicio = time.perf_counter()\n",
        "    compressor = ArvorePPM_C(ordem=ordem, tamanho_alfabeto=256)\n",
        "\n",
        "    with open(entrada, \"rb\") as fin:\n",
        "        while True:\n",
        "            byte = fin.read(1)\n",
        "            if not byte:\n",
        "                break\n",
        "            compressor.codificar_simbolo(byte[0])\n",
        "\n",
        "    dados = compressor.finalizar_compressao()\n",
        "\n",
        "    with open(saida, \"wb\") as fout:\n",
        "        fout.write(dados)\n",
        "\n",
        "    fim = time.perf_counter()\n",
        "    print(f\"Compressão finalizada em {fim - inicio:.2f} segundos.\")\n",
        "\n",
        "    return fim - inicio, compressor\n",
        "\n",
        "\n",
        "def descomprimir(entrada: str, saida: str, ordem: int):\n",
        "    \"\"\"\n",
        "    Descompacta `entrada` para `saida` usando um modelo PPM de ordem `ordem`.\n",
        "\n",
        "    Passos:\n",
        "    - Lê todo o arquivo comprimido em um buffer de bits\n",
        "    - Inicializa ArvorePPM_C em modo decodificação (passando fluxo_bits)\n",
        "    - Chama decodificar_simbolo em loop até encontrar _SIMBOLO_FIM\n",
        "    - Grava bytes reconstruídos em `saida`\n",
        "    \"\"\"\n",
        "    print(f\"\\nIniciando descompressão de '{entrada}'...\")\n",
        "    inicio = time.perf_counter()\n",
        "\n",
        "    with open(entrada, \"rb\") as f:\n",
        "        fluxo_bits = io.BytesIO(f.read())\n",
        "\n",
        "    descompressor = ArvorePPM_C(ordem=ordem, tamanho_alfabeto=256, fluxo_bits=fluxo_bits)\n",
        "\n",
        "    with open(saida, \"wb\") as fout:\n",
        "        while True:\n",
        "            simbolo = descompressor.decodificar_simbolo()\n",
        "            if simbolo == _SIMBOLO_FIM:\n",
        "                break\n",
        "            # Quando simbolo é um inteiro (byte), grava no arquivo\n",
        "            fout.write(bytes([simbolo]))\n",
        "\n",
        "    fim = time.perf_counter()\n",
        "    print(f\"Descompressão finalizada em {fim - inicio:.2f} segundos.\")\n",
        "\n",
        "    return fim - inicio\n",
        "\n",
        "\n",
        "def comparar_arquivos(arq1: str, arq2: str) -> bool:\n",
        "    \"\"\"\n",
        "    Compara dois arquivos em modo binário retornando True se forem idênticos.\n",
        "    Implementado para ser eficiente em memória usando buffer de tamanho fixo.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        buffer = 8192\n",
        "        with open(arq1, 'rb') as f1, open(arq2, 'rb') as f2:\n",
        "            while True:\n",
        "                b1 = f1.read(buffer)\n",
        "                b2 = f2.read(buffer)\n",
        "                if b1 != b2:\n",
        "                    return False\n",
        "                if not b1:\n",
        "                    return True\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def preprocessar_texto(texto: str) -> str:\n",
        "    \"\"\"\n",
        "    Exemplo simples de pré-processamento de texto: normaliza para minúsculas e\n",
        "    remove caracteres que não sejam letras a-z ou espaço.\n",
        "    \"\"\"\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^a-z., ]+', '', texto)\n",
        "    texto = re.sub(r'[\\s]+', ' ', texto)\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7leDFSZtIzlO",
        "outputId": "7c223c0f-be96-4382-c1c7-a262b96fbd66"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Bloco principal de execução (exemplo de uso)\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    nome_entrada = \"files_concat.txt\"\n",
        "    nome_comprimido = \"files_concat.bin\"\n",
        "    nome_descomprimido = \"files_concat_descomprimido.txt\"\n",
        "\n",
        "    # Ordem do modelo PPM. Ordens maiores capturam contextos mais longos\n",
        "    # (melhor modelagem para texto natural) mas consomem mais memória e tempo.\n",
        "    ORDEM_PPM = 4\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1) Compressão\n",
        "    # -----------------------------\n",
        "    # Chamamos a função `comprimir` que lê o arquivo byte-a-byte, codifica\n",
        "    # cada símbolo e retorna o tempo de compressão e a instância do\n",
        "    # compressor (ArvorePPM_C) que contém estatísticas como soma_entropia.\n",
        "    tempo_compressao, compressor = comprimir(nome_entrada, nome_comprimido, ORDEM_PPM)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2) Descompressão\n",
        "    # -----------------------------\n",
        "    # Chamamos `descomprimir` que reconstrói o arquivo a partir do binário\n",
        "    # comprimido usando o mesmo modelo PPM (ordem) durante a decodificação.\n",
        "    tempo_descompressao = descomprimir(nome_comprimido, nome_descomprimido, ORDEM_PPM)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3) Medidas e relatório\n",
        "    # -----------------------------\n",
        "    # Tamanhos em bytes dos arquivos original e comprimido\n",
        "    tamanho_original = os.path.getsize(nome_entrada)\n",
        "    tamanho_comprimido = os.path.getsize(nome_comprimido)\n",
        "\n",
        "    # Comprimento médio em bytes por símbolo (aqui usamos 1 símbolo = 1 byte)\n",
        "    # Se o arquivo original tiver tamanho 0, evitamos divisão por zero\n",
        "    comprimento_medio_bytes_por_simbolo = (tamanho_comprimido) / tamanho_original if tamanho_original > 0 else 0\n",
        "\n",
        "    # Entropia empírica estimada pelo modelo durante a compressão\n",
        "    # Usamos os campos acumulados no objeto compressor: soma_entropia e contagem_simbolos\n",
        "    entropia_fonte = compressor.soma_entropia / compressor.contagem_simbolos if compressor.contagem_simbolos > 0 else 0\n",
        "\n",
        "    # Convertemos comprimento médio para bits/símbolo multiplicando por 8\n",
        "    comprimento_medio_bits_por_simbolo = comprimento_medio_bytes_por_simbolo * 8\n",
        "\n",
        "    # Cálculo da perplexidade para o arquivo comprimido\n",
        "    perplexidade = compressor.calcular_perplexidade()\n",
        "\n",
        "    # - Tempo de compressão/descompressão: em segundos\n",
        "    # - Tamanhos: em bytes\n",
        "    # - Entropia da fonte: em bits por símbolo\n",
        "    # - Comprimento médio: bits por símbolo\n",
        "    print(\"\\n\" + \"=\"*25 + \" RELATÓRIO FINAL \" + \"=\"*25)\n",
        "    print(f\"Tempo de Compressão.....: {tempo_compressao:.2f} segundos\")\n",
        "    print(f\"Tempo de Descompressão..: {tempo_descompressao:.2f} segundos\")\n",
        "    print(f\"Tamanho Original........: {tamanho_original} Bytes\")\n",
        "    print(f\"Tamanho Comprimido......: {tamanho_comprimido} Bytes\")\n",
        "    print(f\"Entropia da Fonte (H(X)): {entropia_fonte:.4f} bits/símbolo\")\n",
        "    print(f\"Comprimento Médio.......: {comprimento_medio_bits_por_simbolo:.4f} bits/símbolo\")\n",
        "    print(f\"Perplexidade do modelo..: {perplexidade:.4f}\")\n",
        "    print(\"-\" * 67)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 4) Verificação de integridade\n",
        "    # -----------------------------\n",
        "    # Comparamos byte a byte o arquivo original com o descomprimido. Se\n",
        "    # forem idênticos, a compressão/descompressão foi lossless.\n",
        "    sao_iguais = comparar_arquivos(nome_entrada, nome_descomprimido)\n",
        "\n",
        "    if sao_iguais:\n",
        "        print(\"Verificação: O arquivo original e o descomprimido são IDÊNTICOS.\")\n",
        "    else:\n",
        "        print(\"Verificação: FALHA! O arquivo original e o descomprimido são DIFERENTES.\")\n",
        "    print(\"=\"*67)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tenta carregar o modelo existente\n",
        "nome_modelo = \"ppm_gutenberg_k_4_pont.pkl\"\n",
        "if os.path.exists(nome_modelo):\n",
        "    print(f\"Carregando modelo PPM do arquivo: {nome_modelo}\")\n",
        "    modelo = ArvorePPM_C.carregar_modelo(nome_modelo)\n",
        "\n",
        "    # Correção para garantir que os objetos especiais tenham a mesma referência\n",
        "    # após o carregamento do modelo.\n",
        "    modelo.simbolo_para_int[_SIMBOLO_ESCAPE] = modelo.tamanho_alfabeto_bytes\n",
        "    modelo.simbolo_para_int[_SIMBOLO_FIM] = modelo.tamanho_alfabeto_bytes + 1\n",
        "    modelo.int_para_simbolo[modelo.tamanho_alfabeto_bytes] = _SIMBOLO_ESCAPE\n",
        "    modelo.int_para_simbolo[modelo.tamanho_alfabeto_bytes + 1] = _SIMBOLO_FIM\n",
        "    # --- FIM DAS LINHAS A SEREM INSERIDAS ---\n",
        "\n",
        "else:\n",
        "    print(f\"Arquivo de modelo não encontrado. Criando um novo modelo.\")\n",
        "    modelo = ArvorePPM_C(ordem=4, tamanho_alfabeto=256)\n",
        "\n",
        "# Restante do código\n",
        "nova_entrada = \"medium_concat.txt\"\n",
        "\n",
        "if os.path.exists(nova_entrada):\n",
        "    with open(nova_entrada, \"r\", encoding=\"utf-8\") as f:\n",
        "        texto_adicional = preprocessar_texto(f.read())\n",
        "\n",
        "    for ch in texto_adicional:\n",
        "        modelo.codificar_simbolo(ord(ch))\n",
        "\n",
        "    # O símbolo de fim não é codificado aqui, pois o treinamento continuará.\n",
        "    # Ele será codificado apenas na finalização da compressão.\n",
        "\n",
        "    modelo.salvar_modelo(nome_modelo)\n",
        "    print(f\"Modelo atualizado e salvo em: {nome_modelo}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Erro: O arquivo de nova entrada '{nova_entrada}' não foi encontrado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFttEoYkID66"
      },
      "outputs": [],
      "source": [
        "def quebrar_linhas_por_caracter(texto: str, max_caracteres: int = 80) -> str:\n",
        "    # Quebra o texto a cada `max_caracteres` caracteres (quebra fixa).\n",
        "    if max_caracteres <= 0:\n",
        "        return texto\n",
        "    linhas = [texto[i:i + max_caracteres] for i in range(0, len(texto), max_caracteres)]\n",
        "    return \"\\n\".join(linhas)\n",
        "\n",
        "def quebrar_linhas_por_palavras(texto: str, palavras_por_linha: int = 15) -> str:\n",
        "    # Quebra o texto em linhas com até `palavras_por_linha`.\n",
        "    if palavras_por_linha <= 0:\n",
        "        return texto\n",
        "    palavras = texto.split()\n",
        "    linhas = [\" \".join(palavras[i:i + palavras_por_linha]) for i in range(0, len(palavras), palavras_por_linha)]\n",
        "    return \"\\n\".join(linhas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carrega o modelo PPM previamente salvo (formato pickle)\n",
        "modelo = ArvorePPM_C.carregar_modelo(\"ppm_gutenberg_1_100mb_k_4_pont.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSVUNQGJIMWO",
        "outputId": "18e0ad3d-b9dc-4950-c5b5-982ed1893e51"
      },
      "outputs": [],
      "source": [
        "# Gera o número passado por parâmetro de símbolos/caracteres a partir do modelo\n",
        "texto_gerado = modelo.gerar_texto(tamanho=400, semente='')\n",
        "\n",
        "# Formata o texto quebrando por palavras (padrão: 15 palavras por linha)\n",
        "texto_formatado = quebrar_linhas_por_palavras(texto_gerado)\n",
        "\n",
        "print(texto_formatado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gera o número passado por parâmetro de símbolos/caracteres a partir do modelo\n",
        "texto_gerado = modelo.gerar_texto_nitidez(tamanho=400, semente='', nitidez=2.0)\n",
        "\n",
        "# Formata o texto quebrando por palavras (padrão: 15 palavras por linha)\n",
        "texto_formatado = quebrar_linhas_por_palavras(texto_gerado)\n",
        "\n",
        "print(texto_formatado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Métrica Distinct-n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt') # Baixa o tokenizador, se necessário\n",
        "\n",
        "def calcular_distinct_n(texto: str, n: int) -> float:\n",
        "    \"\"\"\n",
        "    Calcula a métrica Distinct-n para um dado texto.\n",
        "\n",
        "    Args:\n",
        "    - texto: O texto gerado pelo modelo.\n",
        "    - n: A ordem do n-grama (1 para unigrama, 2 para bigrama, etc.).\n",
        "\n",
        "    Returns:\n",
        "    - A proporção de n-gramas únicos.\n",
        "    \"\"\"\n",
        "    if not texto.strip():\n",
        "        return 0.0\n",
        "\n",
        "    tokens = word_tokenize(texto.lower())\n",
        "    if len(tokens) < n:\n",
        "        return 0.0\n",
        "\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    if not n_grams:\n",
        "        return 0.0\n",
        "\n",
        "    return len(set(n_grams)) / len(n_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerar texto\n",
        "texto_gerado = modelo.gerar_texto_nitidez(tamanho=400, semente=\"the king\", nitidez=2.0)\n",
        "\n",
        "# Calcular as métricas de diversidade\n",
        "distinct_1 = calcular_distinct_n(texto_gerado, 1)\n",
        "distinct_2 = calcular_distinct_n(texto_gerado, 2)\n",
        "\n",
        "print(f\"Texto Gerado: '{texto_gerado}...'\")\n",
        "print(f\"Distinct-1: {distinct_1:.4f}\")\n",
        "print(f\"Distinct-2: {distinct_2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_gerado = modelo.gerar_texto(tamanho=400, semente=\"the king\")\n",
        "\n",
        "# Calcular as métricas de diversidade\n",
        "distinct_1 = calcular_distinct_n(texto_gerado, 1)\n",
        "distinct_2 = calcular_distinct_n(texto_gerado, 2)\n",
        "\n",
        "print(f\"Texto Gerado: '{texto_gerado}...'\")\n",
        "print(f\"Distinct-1: {distinct_1:.4f}\")\n",
        "print(f\"Distinct-2: {distinct_2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carrega o modelo PPM previamente salvo (formato pickle)\n",
        "modelo = ArvorePPM_C.carregar_modelo(\"ppm_gutenberg_k_4_pont.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_gerado = modelo.gerar_texto(tamanho=400, semente=\"the king\")\n",
        "texto_formatado = quebrar_linhas_por_palavras(texto_gerado)\n",
        "\n",
        "print(texto_formatado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_gerado = modelo.gerar_texto_nitidez(tamanho=400, semente=\"the king\", nitidez=2.0)\n",
        "texto_formatado = quebrar_linhas_por_palavras(texto_gerado)\n",
        "\n",
        "print(texto_formatado)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
